---
id: bypassing-cylance-s-ai-malware-detection
title: "AML.CS0003: Bypassing Cylance's AI Malware Detection"
sidebar_label: "Bypassing Cylance's AI Malware Detection"
sidebar_position: 4
---

# AML.CS0003: Bypassing Cylance's AI Malware Detection

## Summary

Researchers at Skylight were able to create a universal bypass string that evades detection by Cylance's AI Malware detector when appended to a malicious file.

## Metadata

- **Case Study ID:** AML.CS0003
- **Incident Date:** 2019
- **Type:** exercise
- **Target:** CylancePROTECT, Cylance Smart Antivirus
- **Actor:** Skylight Cyber

## Attack Procedure

The following steps outline the attack procedure:

### Step 1: Search Open Technical Databases

**Tactic:** [[atlas/tactics/reconnaissance|AML.TA0002: Reconnaissance]]
**Technique:** [[atlas/techniques/reconnaissance/search-open-technical-databases/search-open-technical-databases-overview|AML.T0000: Search Open Technical Databases]]

The researchers read publicly available information about Cylance's AI Malware detector. They gathered this information from various sources such as public talks as well as patent submissions by Cylance.

### Step 2: AI-Enabled Product or Service

**Tactic:** [[atlas/tactics/ai-model-access|AML.TA0000: AI Model Access]]
**Technique:** [[atlas/techniques/ai-model-access/ai-enabled-product-or-service|AML.T0047: AI-Enabled Product or Service]]

The researchers had access to Cylance's AI-enabled malware detection software.

### Step 3: Discover AI Model Outputs

**Tactic:** [[atlas/tactics/discovery|AML.TA0008: Discovery]]
**Technique:** [[atlas/techniques/discovery/discover-ai-model-outputs|AML.T0063: Discover AI Model Outputs]]

The researchers enabled verbose logging, which exposes the inner workings of the ML model, specifically around reputation scoring and model ensembling.

### Step 4: Adversarial AI Attacks

**Tactic:** [[atlas/tactics/resource-development|AML.TA0003: Resource Development]]
**Technique:** [[atlas/techniques/resource-development/develop-capabilities/adversarial-ai-attacks|AML.T0017.000: Adversarial AI Attacks]]

The researchers used the reputation scoring information to reverse engineer which attributes provided what level of positive or negative reputation.
Along the way, they discovered a secondary model which was an override for the first model.
Positive assessments from the second model overrode the decision of the core ML model.

### Step 5: Manual Modification

**Tactic:** [[atlas/tactics/ai-attack-staging|AML.TA0001: AI Attack Staging]]
**Technique:** [[atlas/techniques/ai-attack-staging/craft-adversarial-data/manual-modification|AML.T0043.003: Manual Modification]]

Using this knowledge, the researchers fused attributes of known good files with malware to manually create adversarial malware.

### Step 6: Evade AI Model

**Tactic:** [[atlas/tactics/defense-evasion|AML.TA0007: Defense Evasion]]
**Technique:** [[atlas/techniques/initial-access/evade-ai-model|AML.T0015: Evade AI Model]]

Due to the secondary model overriding the primary, the researchers were effectively able to bypass the ML model.


## Tactics and Techniques Used


| Step | Tactic | Technique |
|---|---|---|
| 1 | [[atlas/tactics/reconnaissance|AML.TA0002: Reconnaissance]] | [[atlas/techniques/reconnaissance/search-open-technical-databases/search-open-technical-databases-overview|AML.T0000: Search Open Technical Databases]] |
| 2 | [[atlas/tactics/ai-model-access|AML.TA0000: AI Model Access]] | [[atlas/techniques/ai-model-access/ai-enabled-product-or-service|AML.T0047: AI-Enabled Product or Service]] |
| 3 | [[atlas/tactics/discovery|AML.TA0008: Discovery]] | [[atlas/techniques/discovery/discover-ai-model-outputs|AML.T0063: Discover AI Model Outputs]] |
| 4 | [[atlas/tactics/resource-development|AML.TA0003: Resource Development]] | [[atlas/techniques/resource-development/develop-capabilities/adversarial-ai-attacks|AML.T0017.000: Adversarial AI Attacks]] |
| 5 | [[atlas/tactics/ai-attack-staging|AML.TA0001: AI Attack Staging]] | [[atlas/techniques/ai-attack-staging/craft-adversarial-data/manual-modification|AML.T0043.003: Manual Modification]] |
| 6 | [[atlas/tactics/defense-evasion|AML.TA0007: Defense Evasion]] | [[atlas/techniques/initial-access/evade-ai-model|AML.T0015: Evade AI Model]] |



## External References

- Skylight Cyber Blog Post, "Cylance, I Kill You!" Available at: https://skylightcyber.com/2019/07/18/cylance-i-kill-you/
- Statement's from Skylight Cyber CEO Available at: https://www.security7.net/news/the-new-cylance-vulnerability-what-you-need-to-know


## References

MITRE Corporation. *Bypassing Cylance's AI Malware Detection (AML.CS0003)*. MITRE ATLAS. Available at: https://atlas.mitre.org/studies/AML.CS0003
