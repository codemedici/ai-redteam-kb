---
id: evasion-of-deep-learning-detector-for-malware-c-c-traffic
title: "AML.CS0000: Evasion of Deep Learning Detector for Malware C&C Traffic"
sidebar_label: "Evasion of Deep Learning Detector for Malware C&C Traffic"
sidebar_position: 1
---

# AML.CS0000: Evasion of Deep Learning Detector for Malware C&C Traffic

## Summary

The Palo Alto Networks Security AI research team tested a deep learning model for malware command and control (C&C) traffic detection in HTTP traffic.
Based on the publicly available [paper by Le et al.](https://arxiv.org/abs/1802.03162), we built a model that was trained on a similar dataset as our production model and had similar performance.
Then we crafted adversarial samples, queried the model, and adjusted the adversarial sample accordingly until the model was evaded.

## Metadata

- **Case Study ID:** AML.CS0000
- **Incident Date:** 2020
- **Type:** exercise
- **Target:** Palo Alto Networks malware detection system
- **Actor:** Palo Alto Networks AI Research Team

## Attack Procedure

The following steps outline the attack procedure:

### Step 1: Pre-Print Repositories

**Tactic:** [[reconnaissance|AML.TA0002: Reconnaissance]]
**Technique:** [[pre-print-repositories|AML.T0000.001: Pre-Print Repositories]]

We identified a machine learning based approach to malicious URL detection as a representative approach and potential target from the paper [URLNet: Learning a URL representation with deep learning for malicious URL detection](https://arxiv.org/abs/1802.03162), which was found on arXiv (a pre-print repository).

### Step 2: Datasets

**Tactic:** [[resource-development|AML.TA0003: Resource Development]]
**Technique:** [[datasets|AML.T0002.000: Datasets]]

We acquired a command and control HTTP traffic  dataset consisting of approximately 33 million benign and 27 million malicious HTTP packet headers.

### Step 3: Create Proxy AI Model

**Tactic:** [[ai-attack-staging|AML.TA0001: AI Attack Staging]]
**Technique:** [[create-proxy-ai-model|AML.T0005: Create Proxy AI Model]]

We trained a model on the HTTP traffic dataset to use as a proxy for the target model.
Evaluation showed a true positive rate of ~ 99% and false positive rate of ~ 0.01%, on average.
Testing the model with a HTTP packet header from known malware command and control traffic samples was detected as malicious with high confidence (> 99%).

### Step 4: Manual Modification

**Tactic:** [[ai-attack-staging|AML.TA0001: AI Attack Staging]]
**Technique:** [[manual-modification|AML.T0043.003: Manual Modification]]

We crafted evasion samples by removing fields from packet header which are typically not used for C&C communication (e.g. cache-control, connection, etc.).

### Step 5: Verify Attack

**Tactic:** [[ai-attack-staging|AML.TA0001: AI Attack Staging]]
**Technique:** [[verify-attack|AML.T0042: Verify Attack]]

We queried the model with our adversarial examples and adjusted them until the model was evaded.

### Step 6: Evade AI Model

**Tactic:** [[defense-evasion|AML.TA0007: Defense Evasion]]
**Technique:** [[evade-ai-model|AML.T0015: Evade AI Model]]

With the crafted samples, we performed online evasion of the ML-based spyware detection model.
The crafted packets were identified as benign with > 80% confidence.
This evaluation demonstrates that adversaries are able to bypass advanced ML detection techniques, by crafting samples that are misclassified by an ML model.


## Tactics and Techniques Used


| Step | Tactic | Technique |
|---|---|---|
| 1 | [[reconnaissance|AML.TA0002: Reconnaissance]] | [[pre-print-repositories|AML.T0000.001: Pre-Print Repositories]] |
| 2 | [[resource-development|AML.TA0003: Resource Development]] | [[datasets|AML.T0002.000: Datasets]] |
| 3 | [[ai-attack-staging|AML.TA0001: AI Attack Staging]] | [[create-proxy-ai-model|AML.T0005: Create Proxy AI Model]] |
| 4 | [[ai-attack-staging|AML.TA0001: AI Attack Staging]] | [[manual-modification|AML.T0043.003: Manual Modification]] |
| 5 | [[ai-attack-staging|AML.TA0001: AI Attack Staging]] | [[verify-attack|AML.T0042: Verify Attack]] |
| 6 | [[defense-evasion|AML.TA0007: Defense Evasion]] | [[evade-ai-model|AML.T0015: Evade AI Model]] |



## External References

- Le, Hung, et al. "URLNet: Learning a URL representation with deep learning for malicious URL detection." arXiv preprint arXiv:1802.03162 (2018). Available at: https://arxiv.org/abs/1802.03162


## References

MITRE Corporation. *Evasion of Deep Learning Detector for Malware C&C Traffic (AML.CS0000)*. MITRE ATLAS. Available at: https://atlas.mitre.org/studies/AML.CS0000
