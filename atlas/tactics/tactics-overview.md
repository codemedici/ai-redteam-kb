---
id: tactics-index
title: ATLAS Tactics
sidebar_label: Overview
sidebar_position: 0
---

# ATLAS Tactics

Tactics represent the "why" of an adversary's actions - the adversary's tactical goals and objectives during an attack.

## All Tactics (16)

| ID | Tactic | Description |
|---|---|---|
| [[reconnaissance|AML.TA0002]] | **Reconnaissance** | The adversary is trying to gather information about the AI system they can use to plan future operations. |
| [[resource-development|AML.TA0003]] | **Resource Development** | The adversary is trying to establish resources they can use to support operations. |
| [[initial-access|AML.TA0004]] | **Initial Access** | The adversary is trying to gain access to the AI system. |
| [[ai-model-access|AML.TA0000]] | **AI Model Access** | The adversary is attempting to gain some level of access to an AI model. |
| [[execution|AML.TA0005]] | **Execution** | The adversary is trying to run malicious code embedded in AI artifacts or software. |
| [[persistence|AML.TA0006]] | **Persistence** | The adversary is trying to maintain their foothold via AI artifacts or software. |
| [[privilege-escalation|AML.TA0012]] | **Privilege Escalation** | The adversary is trying to gain higher-level permissions. |
| [[defense-evasion|AML.TA0007]] | **Defense Evasion** | The adversary is trying to avoid being detected by AI-enabled security software. |
| [[credential-access|AML.TA0013]] | **Credential Access** | The adversary is trying to steal account names and passwords. |
| [[discovery|AML.TA0008]] | **Discovery** | The adversary is trying to figure out your AI environment. |
| [[lateral-movement|AML.TA0015]] | **Lateral Movement** | The adversary is trying to move through your AI environment. |
| [[collection|AML.TA0009]] | **Collection** | The adversary is trying to gather AI artifacts and other related information relevant to their goal. |
| [[ai-attack-staging|AML.TA0001]] | **AI Attack Staging** | The adversary is leveraging their knowledge of and access to the target system to tailor the attack. |
| [[command-and-control|AML.TA0014]] | **Command and Control** | The adversary is trying to communicate with compromised AI systems to control them. |
| [[exfiltration|AML.TA0010]] | **Exfiltration** | The adversary is trying to steal AI artifacts or other information about the AI system. |
| [[impact|AML.TA0011]] | **Impact** | The adversary is trying to manipulate, interrupt, erode confidence in, or destroy your AI systems and data. |

## References

MITRE Corporation. *ATLAS Tactics*. Available at: https://atlas.mitre.org/tactics
