---
id: user-execution-malicious-package
title: "AML.T0011.001: Malicious Package"
sidebar_label: "Malicious Package"
sidebar_position: 8
---

# AML.T0011.001: Malicious Package

> **Sub-Technique of:** [[user-execution|AML.T0011: User Execution]]



Adversaries may develop malicious software packages that when imported by a user have a deleterious effect.
Malicious packages may behave as expected to the user. They may be introduced via [[ai-supply-chain-compromise|AI Supply Chain Compromise]]. They may not present as obviously malicious to the user and may appear to be useful for an AI-related task.

## Metadata

- **Technique ID:** AML.T0011.001
- **Created:** March 12, 2025
- **Last Modified:** March 12, 2025
- **Maturity:** demonstrated

- **Parent Technique:** [[user-execution|AML.T0011: User Execution]]

## Tactics (0)

This technique supports the following tactics:

*No tactics currently associated with this technique.*



## Case Studies (1)


The following case studies demonstrate this technique:

### [[chatgpt-package-hallucination|AML.CS0022: ChatGPT Package Hallucination]]

The user would ultimately load the malicious package, allowing for arbitrary code execution.



## References

MITRE Corporation. *Malicious Package (AML.T0011.001)*. MITRE ATLAS. Available at: https://atlas.mitre.org/techniques/AML.T0011.001
