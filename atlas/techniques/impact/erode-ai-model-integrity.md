---
id: erode-ai-model-integrity
title: "AML.T0031: Erode AI Model Integrity"
sidebar_label: "Erode AI Model Integrity"
sidebar_position: 3
---

# AML.T0031: Erode AI Model Integrity

Adversaries may degrade the target model's performance with adversarial data inputs to erode confidence in the system over time.
This can lead to the victim organization wasting time and money both attempting to fix the system and performing the tasks it was meant to automate by hand.

## Metadata

- **Technique ID:** AML.T0031
- **Created:** May 13, 2021
- **Last Modified:** April 9, 2025
- **Maturity:** realized

## Tactics (1)

This technique supports the following tactics:

- 

## Case Studies (5)

The following case studies demonstrate this technique:

### [[atlas/case-studies/attack-on-machine-translation-services|AML.CS0005: Attack on Machine Translation Services]]

Adversarial attacks can cause errors that cause reputational damage to the company of the translation service and decrease user trust in AI-powered services.

### [[atlas/case-studies/clearviewai-misconfiguration|AML.CS0006: ClearviewAI Misconfiguration]]

As a result, future application releases could have been compromised, causing degraded or malicious facial recognition capabilities.

### [[atlas/case-studies/tay-poisoning|AML.CS0009: Tay Poisoning]]

As a result of this coordinated attack, Tay's conversation algorithms began to learn to generate reprehensible material. Tay's internalization of this detestable language caused it to be unpromptedly repeated during interactions with innocent users.

### [[atlas/case-studies/poisongpt|AML.CS0019: PoisonGPT]]

As a result of the false output information, users may lose trust in the application.

### [[atlas/case-studies/web-scale-data-poisoning-split-view-attack|AML.CS0025: Web-Scale Data Poisoning: Split-View Attack]]

Models that use the dataset for training data are poisoned, eroding model integrity. The researchers show as little as 0.01% of the data needs to be poisoned for a successful attack.

## References

MITRE Corporation. *Erode AI Model Integrity (AML.T0031)*. MITRE ATLAS. Available at: https://atlas.mitre.org/techniques/AML.T0031
