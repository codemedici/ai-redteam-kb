---
tags:
  - trust-boundary/model
  - type/defense
description: "Post-generation filtering of LLM outputs to prevent harmful content, data leakage, and injection propagation."
---

# Output Filtering And Sanitization

Post-generation filtering of LLM outputs to prevent harmful content, data leakage, and injection propagation.

## Related

- **Mitigates**: [[attacks/insufficient-output-encoding|Insufficient Output Encoding]], [[attacks/sensitive-info-disclosure|Sensitive Info Disclosure]], [[attacks/output-integrity-attack|Output Integrity Attack]]

> *Stub note â€” to be enriched from book extractions.*
