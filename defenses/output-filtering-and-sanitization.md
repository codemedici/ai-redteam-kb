---
description: "Post-generation filtering of LLM outputs to prevent harmful content, data leakage, and injection propagation."
tags:
  - trust-boundary/model
  - type/defense
  - target/llm-app
  - target/agent
---

# Output Filtering And Sanitization

Post-generation filtering of LLM outputs to prevent harmful content, data leakage, and injection propagation.

## Related

- **Mitigates**: [[attacks/insecure-prompt-assembly]], [[attacks/insufficient-output-encoding]], [[attacks/jailbreak-policy-bypass]], [[attacks/output-integrity-attack]], [[attacks/pii-in-corpus]], [[attacks/prompt-injection]], [[attacks/prompt-log-data-leakage]], [[attacks/sensitive-info-disclosure]], [[attacks/system-prompt-leakage]], [[attacks/training-data-memorization]], [[attacks/unauthorized-knowledge-disclosure]]

> *Stub note â€” to be enriched from book extractions.*
