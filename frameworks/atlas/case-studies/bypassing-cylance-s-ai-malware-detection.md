---
id: bypassing-cylance-s-ai-malware-detection
title: "AML.CS0003: Bypassing Cylance's AI Malware Detection"
type: case-study
sidebar_position: 4
---

# AML.CS0003: Bypassing Cylance's AI Malware Detection

Researchers at Skylight were able to create a universal bypass string that evades detection by Cylance's AI Malware detector when appended to a malicious file.

## Metadata

- **ID:** AML.CS0003
- **Incident Date:** 2019-09-07
- **Type:** exercise
- **Target:** CylancePROTECT, Cylance Smart Antivirus
- **Actor:** Skylight Cyber

## Procedure

### Step 1: Search Open Technical Databases

**Technique:** [[frameworks/atlas/techniques/reconnaissance/search-open-technical-databases|AML.T0000: Search Open Technical Databases]]

The researchers read publicly available information about Cylance's AI Malware detector. They gathered this information from various sources such as public talks as well as patent submissions by Cylance.

### Step 2: AI-Enabled Product or Service

**Technique:** [[frameworks/atlas/techniques/ai-model-access/ai-enabled-product-or-service|AML.T0047: AI-Enabled Product or Service]]

The researchers had access to Cylance's AI-enabled malware detection software.

### Step 3: Discover AI Model Outputs

**Technique:** [[frameworks/atlas/techniques/discovery/discover-ai-model-outputs|AML.T0063: Discover AI Model Outputs]]

The researchers enabled verbose logging, which exposes the inner workings of the ML model, specifically around reputation scoring and model ensembling.

### Step 4: Adversarial AI Attacks

**Technique:** [[frameworks/atlas/techniques/resource-development/develop-capabilities/develop-capabilities-adversarial-AI-attacks|AML.T0017.000: Adversarial AI Attacks]]

The researchers used the reputation scoring information to reverse engineer which attributes provided what level of positive or negative reputation.
Along the way, they discovered a secondary model which was an override for the first model.
Positive assessments from the second model overrode the decision of the core ML model.

### Step 5: Manual Modification

**Technique:** [[frameworks/atlas/techniques/ai-attack-staging/craft-adversarial-data/craft-adversarial-data-manual-modification|AML.T0043.003: Manual Modification]]

Using this knowledge, the researchers fused attributes of known good files with malware to manually create adversarial malware.

### Step 6: Evade AI Model

**Technique:** [[frameworks/atlas/techniques/initial-access/evade-ai-model|AML.T0015: Evade AI Model]]

Due to the secondary model overriding the primary, the researchers were effectively able to bypass the ML model.

## References

1. [Skylight Cyber Blog Post, "Cylance, I Kill You!"](https://skylightcyber.com/2019/07/18/cylance-i-kill-you/)
2. [Statement's from Skylight Cyber CEO](https://www.security7.net/news/the-new-cylance-vulnerability-what-you-need-to-know)
