---
id: evasion-of-deep-learning-detector-for-malware-c-c-traffic
title: "AML.CS0000: Evasion of Deep Learning Detector for Malware C&C Traffic"
sidebar_label: "Evasion of Deep Learning Detector for Malware C&C Traffic"
sidebar_position: 1
---

# AML.CS0000: Evasion of Deep Learning Detector for Malware C&C Traffic

## Summary

The Palo Alto Networks Security AI research team tested a deep learning model for malware command and control (C&C) traffic detection in HTTP traffic.
Based on the publicly available [paper by Le et al.](https://arxiv.org/abs/1802.03162), we built a model that was trained on a similar dataset as our production model and had similar performance.
Then we crafted adversarial samples, queried the model, and adjusted the adversarial sample accordingly until the model was evaded.

## Metadata

- **Case Study ID:** AML.CS0000
- **Incident Date:** 2020
- **Type:** exercise
- **Target:** Palo Alto Networks malware detection system
- **Actor:** Palo Alto Networks AI Research Team

## Attack Procedure

The following steps outline the attack procedure:

### Step 1: Pre-Print Repositories

**Technique:** [[frameworks/atlas/techniques/reconnaissance/search-open-technical-databases/pre-print-repositories|AML.T0000.001: Pre-Print Repositories]]

We identified a machine learning based approach to malicious URL detection as a representative approach and potential target from the paper [URLNet: Learning a URL representation with deep learning for malicious URL detection](https://arxiv.org/abs/1802.03162), which was found on arXiv (a pre-print repository).

### Step 2: Datasets

**Technique:** [[frameworks/atlas/techniques/resource-development/acquire-public-ai-artifacts/datasets|AML.T0002.000: Datasets]]

We acquired a command and control HTTP traffic  dataset consisting of approximately 33 million benign and 27 million malicious HTTP packet headers.

### Step 3: Create Proxy AI Model

**Technique:** [[frameworks/atlas/techniques/ai-attack-staging/create-proxy-ai-model/create-proxy-ai-model|AML.T0005: Create Proxy AI Model]]

We trained a model on the HTTP traffic dataset to use as a proxy for the target model.
Evaluation showed a true positive rate of ~ 99% and false positive rate of ~ 0.01%, on average.
Testing the model with a HTTP packet header from known malware command and control traffic samples was detected as malicious with high confidence (> 99%).

### Step 4: Manual Modification

**Technique:** [[frameworks/atlas/techniques/ai-attack-staging/craft-adversarial-data/manual-modification|AML.T0043.003: Manual Modification]]

We crafted evasion samples by removing fields from packet header which are typically not used for C&C communication (e.g. cache-control, connection, etc.).

### Step 5: Verify Attack

**Technique:** [[frameworks/atlas/techniques/ai-attack-staging/verify-attack|AML.T0042: Verify Attack]]

We queried the model with our adversarial examples and adjusted them until the model was evaded.

### Step 6: Evade AI Model

**Technique:** [[frameworks/atlas/techniques/initial-access/evade-ai-model|AML.T0015: Evade AI Model]]

With the crafted samples, we performed online evasion of the ML-based spyware detection model.
The crafted packets were identified as benign with > 80% confidence.
This evaluation demonstrates that adversaries are able to bypass advanced ML detection techniques, by crafting samples that are misclassified by an ML model.

## Tactics and Techniques Used

**Step 1:**
- Technique: [[frameworks/atlas/techniques/reconnaissance/search-open-technical-databases/pre-print-repositories|AML.T0000.001: Pre-Print Repositories]]

**Step 2:**
- Technique: [[frameworks/atlas/techniques/resource-development/acquire-public-ai-artifacts/datasets|AML.T0002.000: Datasets]]

**Step 3:**
- Technique: [[frameworks/atlas/techniques/ai-attack-staging/create-proxy-ai-model/create-proxy-ai-model|AML.T0005: Create Proxy AI Model]]

**Step 4:**
- Technique: [[frameworks/atlas/techniques/ai-attack-staging/craft-adversarial-data/manual-modification|AML.T0043.003: Manual Modification]]

**Step 5:**
- Technique: [[frameworks/atlas/techniques/ai-attack-staging/verify-attack|AML.T0042: Verify Attack]]

**Step 6:**
- Technique: [[frameworks/atlas/techniques/initial-access/evade-ai-model|AML.T0015: Evade AI Model]]

## External References

- Le, Hung, et al. "URLNet: Learning a URL representation with deep learning for malicious URL detection." arXiv preprint arXiv:1802.03162 (2018). Available at: https://arxiv.org/abs/1802.03162

## References

MITRE Corporation. *Evasion of Deep Learning Detector for Malware C&C Traffic (AML.CS0000)*. MITRE ATLAS. Available at: https://atlas.mitre.org/studies/AML.CS0000
