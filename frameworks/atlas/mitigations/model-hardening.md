---
id: model-hardening
title: "AML.M0003: Model Hardening"
sidebar_label: "Model Hardening"
sidebar_position: 4
type: mitigation
---

# AML.M0003: Model Hardening

Use techniques to make AI models robust to adversarial inputs such as adversarial training or network distillation.

## Metadata

- **Mitigation ID:** AML.M0003
- **Created:** 2023-04-12
- **Last Modified:** 2025-12-23
- **Category:** Technical - ML
- **ML Lifecycle:** Data Preparation, ML Model Engineering

## Techniques (8)

- [[frameworks/atlas/techniques/initial-access/evade-ai-model|AML.T0015: Evade AI Model]] — Hardened models are more difficult to evade.
- [[frameworks/atlas/techniques/impact/erode-ai-model-integrity|AML.T0031: Erode AI Model Integrity]] — Hardened models are less susceptible to integrity attacks.
- [[frameworks/atlas/techniques/ai-attack-staging/craft-adversarial-data|AML.T0043: Craft Adversarial Data]] — Hardened models are more robust to adversarial inputs.
- [[frameworks/atlas/techniques/ai-attack-staging/craft-adversarial-data/craft-adversarial-data-black-box-optimization|AML.T0043.001: Black-Box Optimization]] — Hardened models are more robust to adversarial inputs.
- [[frameworks/atlas/techniques/ai-attack-staging/craft-adversarial-data/craft-adversarial-data-black-box-transfer|AML.T0043.002: Black-Box Transfer]] — Hardened models are more robust to adversarial inputs.
- [[frameworks/atlas/techniques/ai-attack-staging/craft-adversarial-data/craft-adversarial-data-manual-modification|AML.T0043.003: Manual Modification]] — Hardened models are more robust to adversarial inputs.
- [[frameworks/atlas/techniques/ai-attack-staging/craft-adversarial-data/craft-adversarial-data-white-box-optimization|AML.T0043.000: White-Box Optimization]] — Hardened models are more robust to adversarial inputs.
- [[frameworks/atlas/techniques/ai-attack-staging/craft-adversarial-data/craft-adversarial-data-insert-backdoor-trigger|AML.T0043.004: Insert Backdoor Trigger]] — Hardened models are more robust to adversarial inputs.
