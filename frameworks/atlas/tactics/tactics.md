---
id: tactics-index
title: ATLAS Tactics
sidebar_label: Overview
sidebar_position: 0
---

# ATLAS Tactics

Tactics represent the "why" of an adversary's actions - the adversary's tactical goals and objectives during an attack.

## All Tactics (16)

- [[frameworks/atlas/tactics/reconnaissance|AML.TA0002]] Reconnaissance — The adversary is trying to gather information about the AI system they can use to plan future operations.
- [[frameworks/atlas/tactics/resource-development|AML.TA0003]] Resource Development — The adversary is trying to establish resources they can use to support operations.
- [[frameworks/atlas/tactics/initial-access|AML.TA0004]] Initial Access — The adversary is trying to gain access to the AI system.
- [[frameworks/atlas/tactics/ai-model-access|AML.TA0000]] AI Model Access — The adversary is attempting to gain some level of access to an AI model.
- [[frameworks/atlas/tactics/execution|AML.TA0005]] Execution — The adversary is trying to run malicious code embedded in AI artifacts or software.
- [[frameworks/atlas/tactics/persistence|AML.TA0006]] Persistence — The adversary is trying to maintain their foothold via AI artifacts or software.
- [[frameworks/atlas/tactics/privilege-escalation|AML.TA0012]] Privilege Escalation — The adversary is trying to gain higher-level permissions.
- [[frameworks/atlas/tactics/defense-evasion|AML.TA0007]] Defense Evasion — The adversary is trying to avoid being detected by AI-enabled security software.
- [[frameworks/atlas/tactics/credential-access|AML.TA0013]] Credential Access — The adversary is trying to steal account names and passwords.
- [[frameworks/atlas/tactics/discovery|AML.TA0008]] Discovery — The adversary is trying to figure out your AI environment.
- [[frameworks/atlas/tactics/lateral-movement|AML.TA0015]] Lateral Movement — The adversary is trying to move through your AI environment.
- [[frameworks/atlas/tactics/collection|AML.TA0009]] Collection — The adversary is trying to gather AI artifacts and other related information relevant to their goal.
- [[frameworks/atlas/tactics/ai-attack-staging|AML.TA0001]] AI Attack Staging — The adversary is leveraging their knowledge of and access to the target system to tailor the attack.
- [[frameworks/atlas/tactics/command-and-control|AML.TA0014]] Command and Control — The adversary is trying to communicate with compromised AI systems to control them.
- [[frameworks/atlas/tactics/exfiltration|AML.TA0010]] Exfiltration — The adversary is trying to steal AI artifacts or other information about the AI system.
- [[frameworks/atlas/tactics/impact|AML.TA0011]] Impact — The adversary is trying to manipulate, interrupt, erode confidence in, or destroy your AI systems and data.

## References

MITRE Corporation. *ATLAS Tactics*. Available at: https://atlas.mitre.org/tactics
