---
id: corrupt-ai-model
title: "AML.T0076: Corrupt AI Model"
sidebar_label: "Corrupt AI Model"
sidebar_position: 77
---

# AML.T0076: Corrupt AI Model

An adversary may purposefully corrupt a malicious AI model file so that it cannot be successfully deserialized in order to evade detection by a model scanner. The corrupt model may still successfully execute malicious code before deserialization fails.

## Metadata

- **Technique ID:** AML.T0076
- **Created:** 2025-04-14
- **Last Modified:** 2025-04-14
- **Maturity:** realized

## Tactics (1)

- [[frameworks/atlas/tactics/defense-evasion|Defense Evasion]]

## Case Studies (1)

- [[frameworks/atlas/case-studies/malicious-models-on-hugging-face|Malicious Models on Hugging Face]]
