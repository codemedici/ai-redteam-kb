---
id: erode-ai-model-integrity
title: "AML.T0031: Erode AI Model Integrity"
sidebar_label: "Erode AI Model Integrity"
sidebar_position: 32
---

# AML.T0031: Erode AI Model Integrity

Adversaries may degrade the target model's performance with adversarial data inputs to erode confidence in the system over time.
This can lead to the victim organization wasting time and money both attempting to fix the system and performing the tasks it was meant to automate by hand.

## Metadata

- **Technique ID:** AML.T0031
- **Created:** 2021-05-13
- **Last Modified:** 2025-04-09
- **Maturity:** realized

## Tactics (1)

- [[frameworks/atlas/tactics/impact|Impact]]

## Case Studies (6)

- [[frameworks/atlas/case-studies/attack-on-machine-translation-services|Attack on Machine Translation Services]]
- [[frameworks/atlas/case-studies/clearviewai-misconfiguration|ClearviewAI Misconfiguration]]
- [[frameworks/atlas/case-studies/tay-poisoning|Tay Poisoning]]
- [[frameworks/atlas/case-studies/poisongpt|PoisonGPT]]
- [[frameworks/atlas/case-studies/web-scale-data-poisoning-split-view-attack|Web-Scale Data Poisoning: Split-View Attack]]
- [[frameworks/atlas/case-studies/openclaw-command-control-via-prompt-injection|OpenClaw Command & Control via Prompt Injection]]
