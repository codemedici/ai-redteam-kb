---
id: manipulate-AI-model-embed-malware
title: "AML.T0018.002: Embed Malware"
sidebar_label: "Embed Malware"
sidebar_position: 18003
---

# AML.T0018.002: Embed Malware

Adversaries may embed malicious code into AI Model files.
AI models may be packaged as a combination of instructions and weights.
Some formats such as pickle files are unsafe to deserialize because they can contain unsafe calls such as exec.
Models with embedded malware may still operate as expected.
It may allow them to achieve Execution, Command & Control, or Exfiltrate Data.

## Metadata

- **Technique ID:** AML.T0018.002
- **Created:** 2025-04-09
- **Last Modified:** 2025-04-09
- **Maturity:** realized

## Parent Technique

**Parent Technique:** AML.T0018 — Manipulate AI Model

## Tactics (2)

- [[frameworks/atlas/tactics/persistence|Persistence]]
- [[frameworks/atlas/tactics/ai-attack-staging|AI Attack Staging]]

## Mitigations (1)

- [[frameworks/atlas/mitigations/code-signing|AML.M0013: Code Signing]] — Code signing provides a guarantee that the model has not been manipulated after signing took place.

## Case Studies (2)

- [[frameworks/atlas/case-studies/organization-confusion-on-hugging-face|Organization Confusion on Hugging Face]]
- [[frameworks/atlas/case-studies/malicious-models-on-hugging-face|Malicious Models on Hugging Face]]
