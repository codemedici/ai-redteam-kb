---
id: search-open-ai-vulnerability-analysis
title: "AML.T0001: Search Open AI Vulnerability Analysis"
sidebar_label: "Search Open AI Vulnerability Analysis"
sidebar_position: 2
---

# AML.T0001: Search Open AI Vulnerability Analysis

Much like the [Search Open Technical Databases](/techniques/AML.T0000), there is often ample research available on the vulnerabilities of common AI models. Once a target has been identified, an adversary will likely try to identify any pre-existing work that has been done for this class of models.
This will include not only reading academic papers that may identify the particulars of a successful attack, but also identifying pre-existing implementations of those attacks. The adversary may obtain [Adversarial AI Attack Implementations](/techniques/AML.T0016.000) or develop their own [Adversarial AI Attacks](/techniques/AML.T0017.000) if necessary.

## Metadata

- **Technique ID:** AML.T0001
- **Created:** 2021-05-13
- **Last Modified:** 2025-04-17
- **Maturity:** demonstrated

## Tactics (1)

- [[frameworks/atlas/tactics/reconnaissance|Reconnaissance]]

## Case Studies (2)

- [[frameworks/atlas/case-studies/confusing-antimalware-neural-networks|Confusing Antimalware Neural Networks]]
- [[frameworks/atlas/case-studies/achieving-code-execution-in-mathgpt-via-prompt-injection|Achieving Code Execution in MathGPT via Prompt Injection]]
