---
id: develop-capabilities-adversarial-AI-attacks
title: "AML.T0017.000: Adversarial AI Attacks"
sidebar_label: "Adversarial AI Attacks"
sidebar_position: 17001
---

# AML.T0017.000: Adversarial AI Attacks

Adversaries may develop their own adversarial attacks.
They may leverage existing libraries as a starting point ([Adversarial AI Attack Implementations](/techniques/AML.T0016.000)).
They may implement ideas described in public research papers or develop custom made attacks for the victim model.

## Metadata

- **Technique ID:** AML.T0017.000
- **Created:** 2023-10-25
- **Last Modified:** 2025-04-09
- **Maturity:** demonstrated

## Parent Technique

**Parent Technique:** AML.T0017 â€” Develop Capabilities

## Tactics (1)

- [[frameworks/atlas/tactics/resource-development|Resource Development]]

## Case Studies (4)

- [[frameworks/atlas/case-studies/botnet-domain-generation-algorithm-dga-detection-evasion|Botnet Domain Generation Algorithm (DGA) Detection Evasion]]
- [[frameworks/atlas/case-studies/bypassing-cylance-s-ai-malware-detection|Bypassing Cylance's AI Malware Detection]]
- [[frameworks/atlas/case-studies/backdoor-attack-on-deep-learning-models-in-mobile-apps|Backdoor Attack on Deep Learning Models in Mobile Apps]]
- [[frameworks/atlas/case-studies/confusing-antimalware-neural-networks|Confusing Antimalware Neural Networks]]
