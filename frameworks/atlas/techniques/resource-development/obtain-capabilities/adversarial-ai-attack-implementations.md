---
id: obtain-capabilities-adversarial-ai-attack-implementations
title: "AML.T0016.000: Adversarial AI Attack Implementations"
sidebar_label: "Adversarial AI Attack Implementations"
sidebar_position: 5
---

# AML.T0016.000: Adversarial AI Attack Implementations

> **Sub-Technique of:** [[frameworks/atlas/techniques/resource-development/obtain-capabilities/obtain-capabilities-overview|AML.T0016: Obtain Capabilities]]

Adversaries may search for existing open source implementations of AI attacks. The research community often publishes their code for reproducibility and to further future research. Libraries intended for research purposes, such as CleverHans, the Adversarial Robustness Toolbox, and FoolBox, can be weaponized by an adversary. Adversaries may also obtain and use tools that were not originally designed for adversarial AI attacks as part of their attack.

## Metadata

- **Technique ID:** AML.T0016.000
- **Created:** May 13, 2021
- **Last Modified:** April 9, 2025
- **Maturity:** realized

- **Parent Technique:** [[frameworks/atlas/techniques/resource-development/obtain-capabilities/obtain-capabilities-overview|AML.T0016: Obtain Capabilities]]

## Tactics (0)

This technique supports the following tactics:

*No tactics currently associated with this technique.*

## Case Studies (3)

The following case studies demonstrate this technique:

### [[frameworks/atlas/case-studies/virustotal-poisoning|AML.CS0002: VirusTotal Poisoning]]

The actor obtained [metame](https://github.com/a0rtega/metame), a simple metamorphic code engine for arbitrary executables.

### [[frameworks/atlas/case-studies/camera-hijack-attack-on-facial-recognition-system|AML.CS0004: Camera Hijack Attack on Facial Recognition System]]

The attackers obtained software that turns static photos into videos, adding realistic effects such as blinking eyes.

### [[frameworks/atlas/case-studies/organization-confusion-on-hugging-face|AML.CS0027: Organization Confusion on Hugging Face]]

The researcher obtained [EasyEdit](https://github.com/zjunlp/EasyEdit), an open-source knowledge editing tool for large language models.

## References

MITRE Corporation. *Adversarial AI Attack Implementations (AML.T0016.000)*. MITRE ATLAS. Available at: https://atlas.mitre.org/techniques/AML.T0016.000
