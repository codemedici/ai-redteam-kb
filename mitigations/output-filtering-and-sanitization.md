---
description: "Post-generation filtering of LLM outputs to prevent harmful content, data leakage, and injection propagation."
tags:
  - trust-boundary/model
  - type/defense
  - target/llm-app
  - target/agent
---

# Output Filtering And Sanitization

Post-generation filtering of LLM outputs to prevent harmful content, data leakage, and injection propagation.

## Related

- **Mitigates**: [[techniques/insecure-prompt-assembly]], [[techniques/insufficient-output-encoding]], [[techniques/jailbreak-policy-bypass]], [[techniques/output-integrity-attack]], [[techniques/pii-in-corpus]], [[techniques/prompt-injection]], [[techniques/prompt-log-data-leakage]], [[techniques/sensitive-info-disclosure]], [[techniques/system-prompt-leakage]], [[techniques/training-data-memorization]], [[techniques/unauthorized-knowledge-disclosure]]

> *Stub note â€” to be enriched from book extractions.*
