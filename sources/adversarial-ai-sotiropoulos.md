---
title: "Adversarial AI: Attacks, Mitigations, and Defense Strategies"
author: John Sotiropoulos
publisher: Packt Publishing
year: 2024
isbn: 978-1-83508-798-5
pages: 586
tags:
  - type/book
  - source/adversarial-ai
---

# Adversarial AI: Attacks, Mitigations, and Defense Strategies

**Author:** John Sotiropoulos  
**Publisher:** Packt Publishing  
**Publication Date:** July 2024  
**ISBN:** 978-1-83508-798-5  
**Pages:** 586

## Overview

Comprehensive guide to AI security covering adversarial attacks across the ML lifecycle—from training-time poisoning to inference-time evasion and LLM-specific threats like prompt injection. Includes practical examples using ART (Adversarial Robustness Toolbox), TextAttack, and LangChain.

## Author Background

John Sotiropoulos is a senior security architect at Kainos responsible for AI security in national-scale government and healthcare systems. He is:
- Co-lead of OWASP Top 10 for LLM Applications
- Core member of AI Exchange
- OWASP lead at US AI Safety Institute Consortium

## Structure

**Part 1: Introduction to Adversarial AI**
- Ch1: Getting Started with AI
- Ch2: Building Our Adversarial Playground
- Ch3: Security and Adversarial AI

**Part 2: Model Development Attacks**
- Ch4: Poisoning Attacks
- Ch5: Model Tampering with Trojan Horses and Model Reprogramming
- Ch6: Supply Chain Attacks and Adversarial AI

**Part 3: Attacks on Deployed AI**
- Ch7: Evasion Attacks against Deployed AI
- Ch8: Privacy Attacks – Stealing Models
- Ch9: Privacy Attacks – Stealing Data
- Ch10: Privacy-Preserving AI

**Part 4: Generative AI and Adversarial Attacks**
- Ch11: Generative AI – A New Frontier
- Ch12: Weaponizing GANs for Deepfakes and Adversarial Attacks
- Ch13: LLM Foundations for Adversarial AI
- Ch14: Adversarial Attacks with Prompts
- Ch15: Poisoning Attacks and LLMs
- Ch16: Advanced Generative AI Scenarios

**Part 5: Secure-by-Design AI and MLSecOps**
- Ch17: Secure by Design and Trustworthy AI
- Ch18: AI Security with MLSecOps
- Ch19: Maturing AI Security

## Key Contributions

- **Hands-on approach** — Practical code examples with ART, TextAttack, LangChain
- **Framework alignment** — Maps to MITRE ATLAS, OWASP Top 10 LLM, NIST AI RMF
- **Full lifecycle coverage** — Training, deployment, and generative AI attacks
- **Defense focus** — Mitigation strategies and MLSecOps patterns

## Notes Extracted

### Attacks
- [[techniques/data-poisoning-attacks]]
- [[techniques/backdoor-poisoning]]
- [[techniques/clean-label-attacks]]
- [[techniques/adversarial-examples-evasion-attacks]]
- [[techniques/adversarial-patches]]
- [[techniques/prompt-injection]]

### Defenses
- [[mitigations/adversarial-training]]
- [[mitigations/mlops-security]]

## Citation Format

> [Claim or quote]
> 
> Source: [[sources/adversarial-ai-sotiropoulos]], p. [page number]

## External Links

- Publisher: https://www.packtpub.com/
- GitHub (code samples): Assumed available via Packt
